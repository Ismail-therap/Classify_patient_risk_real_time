{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ppf_bis.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Yy0WHpW3X9oX",
        "9SwIjOX9frk6",
        "ZjxFdZTXBZWb",
        "AabTJc6dflSy",
        "DosPYRjLfcoB",
        "5gHJ4YRbnmWJ",
        "aBusNmsKpc2Z",
        "NwwLDouezDLc",
        "VpMowosc0Bzf"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vitaldb/examples/blob/master/eeg_mac.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy0WHpW3X9oX"
      },
      "source": [
        "# 뇌파로부터 마취제 농도 예측 인공지능 모델 실습\n",
        "Sevoflurane 마취 중 뇌파로부터 마취제 농도(age related MAC) 예측 모델\n",
        "\n",
        "## VitalDB 데이터 셋 이용\n",
        "본 예제에서는 오픈 생체 신호 데이터셋인 VitalDB를 이용하는 모든 사용자는 반드시 아래 Data Use Agreement에 동의하여야 합니다.\n",
        "\n",
        "https://vitaldb.net/data-bank/?query=guide&documentId=13qqajnNZzkN7NZ9aXnaQ-47NWy7kx-a6gbrcEsi-gak&sectionId=h.usmoena3l4rb\n",
        "\n",
        "동의하지 않을 경우 이 창을 닫으세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9SwIjOX9frk6"
      },
      "source": [
        "## 본 프로그램에서 이용할 라이브러리 설치 및 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ch6czkFZfw_G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e82d5047-95b9-4501-f889-efa5aa1c18e2"
      },
      "source": [
        "!pip install vitaldb\n",
        "\n",
        "import vitaldb\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import scipy.signal\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import itertools as it\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vitaldb\n",
            "  Downloading vitaldb-0.0.11-py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from vitaldb) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vitaldb) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from vitaldb) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->vitaldb) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->vitaldb) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->vitaldb) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vitaldb) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vitaldb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vitaldb) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vitaldb) (2021.5.30)\n",
            "Installing collected packages: vitaldb\n",
            "Successfully installed vitaldb-0.0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjxFdZTXBZWb"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AabTJc6dflSy"
      },
      "source": [
        "VitalDB Web API를 통해 데이터 로딩\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0b_TyfelWg6e"
      },
      "source": [
        "cachefile = '{}sec_{}cases.npz'.format(SEGLEN // SRATE, MAX_CASES)\n",
        "if os.path.exists(cachefile):\n",
        "    dat = np.load(cachefile)\n",
        "    x, y, b, c = dat['x'], dat['y'], dat['b'], dat['c']\n",
        "else:\n",
        "    df_trks = pd.read_csv(\"https://api.vitaldb.net/trks\")  # 트랙 정보\n",
        "    df_cases = pd.read_csv(\"https://api.vitaldb.net/cases\")  # 환자 정보\n",
        "\n",
        "    # 데이터 로딩 시 컬럼 순서\n",
        "    EEG = 0\n",
        "    SEVO = 1\n",
        "    BIS = 2\n",
        "\n",
        "    # inclusion & exclusion criteria\n",
        "    caseids = set(df_cases.loc[df_cases['age'] > 18, 'caseid']) &\\\n",
        "        set(df_trks.loc[df_trks['tname'] == 'BIS/EEG1_WAV', 'caseid']) &\\\n",
        "        set(df_trks.loc[df_trks['tname'] == 'BIS/BIS', 'caseid']) &\\\n",
        "        set(df_trks.loc[df_trks['tname'] == 'Primus/EXP_SEVO', 'caseid'])\n",
        "\n",
        "    x = []  \n",
        "    y = []  # sevo\n",
        "    b = []  # bis\n",
        "    c = []  # caseids\n",
        "    icase = 0  # 현재까지 로딩된 케이스 수\n",
        "    for caseid in caseids:\n",
        "        print('loading {} ({}/{})'.format(caseid, icase, MAX_CASES), end='...', flush=True)\n",
        "\n",
        "        # 아래 값들이 있으면 제외\n",
        "        if np.any(vitaldb.load_case(caseid, 'Orchestra/PPF20_CE') > 0.2):\n",
        "            print('propofol')\n",
        "            continue\n",
        "        if np.any(vitaldb.load_case(caseid, 'Primus/EXP_DES') > 1):\n",
        "            print('desflurane')\n",
        "            continue\n",
        "        if np.any(vitaldb.load_case(caseid, 'Primus/FEN2O') > 2):\n",
        "            print('n2o')\n",
        "            continue\n",
        "        if np.any(vitaldb.load_case(caseid, 'Orchestra/RFTN50_CE') > 0.2):\n",
        "            print('remifentanil')\n",
        "            continue\n",
        "\n",
        "        # extract data\n",
        "        vals = vitaldb.load_case(caseid, ['BIS/EEG1_WAV', 'Primus/EXP_SEVO', 'BIS/BIS'], 1 / SRATE)\n",
        "        if np.nanmax(vals[:, SEVO]) < 1:\n",
        "            print('all sevo <= 1')\n",
        "            continue\n",
        "\n",
        "        # convert etsevo to the age related mac\n",
        "        age = df_cases.loc[df_cases['caseid'] == caseid, 'age'].values[0]\n",
        "        vals[:, SEVO] /= 1.80 * 10 ** (-0.00269 * (age - 40))\n",
        "\n",
        "        if not np.any(vals[:, BIS] > 0):\n",
        "            print('all bis <= 0')\n",
        "            continue\n",
        "\n",
        "        # 뇌파가 잘 나와야 하기 때문에 bis가 잘 나온 곳 부터 시작함\n",
        "        valid_bis_idx = np.where(vals[:, BIS] > 0)[0]\n",
        "        first_bis_idx = valid_bis_idx[0]\n",
        "        last_bis_idx = valid_bis_idx[-1]\n",
        "        vals = vals[first_bis_idx:last_bis_idx + 1, :]\n",
        "\n",
        "        if len(vals) < 1800 * SRATE:  # 30분 이하인 case는 사용하지 않음\n",
        "            print('{} len < 30 min'.format(caseid))\n",
        "            continue\n",
        "\n",
        "        # MAC 값과 BIS 값은 5초까지 뒤로 채움\n",
        "        vals[:, SEVO:] = pd.DataFrame(vals[:, SEVO:]).ffill(limit=5 * SRATE).values\n",
        "\n",
        "        # 1초 간격으로 데이터 추출\n",
        "        # case 시작 부터 종료까지 dataset 에 넣음\n",
        "        oldlen = len(y)\n",
        "        for irow in range(SEGLEN, len(vals), SRATE):\n",
        "            bis = vals[irow, BIS]\n",
        "            mac = vals[irow, SEVO]\n",
        "            if np.isnan(bis) or np.isnan(mac) or bis == 0:\n",
        "                continue\n",
        "            # dataset 에 추가\n",
        "            eeg = vals[irow - SEGLEN:irow, EEG]\n",
        "            x.append(eeg)\n",
        "            y.append(mac)\n",
        "            b.append(bis)\n",
        "            c.append(caseid)\n",
        "\n",
        "        # valid case\n",
        "        icase += 1\n",
        "        print('{} samples read -> total {} samples ({}/{})'.format(len(y) - oldlen, len(y), icase, MAX_CASES))\n",
        "        if icase >= MAX_CASES:\n",
        "            break\n",
        "\n",
        "    # 입력 데이터셋을 numpy array로 변경\n",
        "    x = np.array(x)\n",
        "    y = np.array(y)\n",
        "    b = np.array(b)\n",
        "    c = np.array(c)\n",
        "\n",
        "    # save cahce file\n",
        "    np.savez(cachefile, x=x, y=y, b=b, c=c)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xzuBetNgW5xv"
      },
      "source": [
        "Case ID 선택(inclusion, exclusion criteria)\n",
        "- 2시간 이상\n",
        "- 전신 마취\n",
        "- 18세 이상\n",
        "- PPF20_VOL, RFTN20_VOL, PPF20_CE, RFTN20_CE, BIS 트랙이 존재\n",
        "- 몸무게 35 kg 이상"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qsz5TKVf6Nb"
      },
      "source": [
        "caseids = list(\n",
        "  set(df_trks[df_trks['tname'] == 'Orchestra/PPF20_VOL']['caseid']) &\n",
        "  set(df_trks[df_trks['tname'] == 'Orchestra/RFTN20_VOL']['caseid']) &\n",
        "  set(df_trks[df_trks['tname'] == 'Orchestra/PPF20_CE']['caseid']) &\n",
        "  set(df_trks[df_trks['tname'] == 'Orchestra/RFTN20_CE']['caseid']) &\n",
        "  set(df_trks[df_trks['tname'] == 'BIS/BIS']['caseid']) & \n",
        "  set(df_cases[df_cases['age'] > 18]['caseid']) & \n",
        "  set(df_cases[df_cases['weight'] > 35]['caseid']) &\n",
        "  set(df_cases[df_cases['caseend'] > 7200]['caseid']) &\n",
        "  set(df_cases[df_cases['ane_type'] == 'General']['caseid'])\n",
        "  )\n",
        "np.random.shuffle(caseids)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBusNmsKpc2Z"
      },
      "source": [
        "# 데이터 전처리\n",
        "- dataset을 담을 변수를 설정\n",
        "- propofol(ppf20), remifentanil(rftn20), bis를 로딩한다\n",
        "- 기록된 데이터가 짧거나, drug infusion이 실제 없었던 케이스, bis값이 적절하지 않은 케이스는 거르기\n",
        "- 결측값 및 음수 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6CHJpySrDxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19bb8c43-25ab-40af-934e-23fdc102c71b"
      },
      "source": [
        "# vital 파일로부터 dataset 을 만듬\n",
        "x_ppf_dose = []  # 각 레코드의 프로포폴 주입량\n",
        "x_rft_dose = []  # 각 레코드의 레미펜타닐 주입량\n",
        "x_aswh = []  # 각 레코드의 나이, 성별, 키, 몸무게\n",
        "x_caseid = []  # 각 레코드의 caseid\n",
        "y = []  # 각 레코드의 출력값 (bis)\n",
        "y_old = []  # 고전적 모델의 예측값\n",
        "\n",
        "LSTM_TIMEPOINTS = 180\n",
        "LSTM_NODES = 8\n",
        "FNN_NODES = 16\n",
        "BATCH_SIZE = 256  # 한번에 처리할 레코드 수 (GPU 메모리 용량에 따라 결정)\n",
        "MAX_CASES = 50  # 본 예제에서 사용할 최대 case 수\n",
        "\n",
        "# 데이터 로딩했을 때 컬럼 순서\n",
        "PPF_DOSE = 0\n",
        "RFT_DOSE = 1\n",
        "PPF_CE = 2\n",
        "RFT_CE = 3\n",
        "BIS = 4\n",
        "\n",
        "icase = 0  # 현재 로딩 중인 케이스 번호\n",
        "ncase = min(MAX_CASES, len(caseids))\n",
        "for caseid in caseids:  # 본 연구에 사용할 각 case에 대하여\n",
        "    print('loading {} ({}/{})'.format(caseid, icase, ncase), end='...', flush=True)\n",
        "\n",
        "    # 10초 간격 데이터 추출\n",
        "    vals = vitaldb.load_case(caseid, ['Orchestra/PPF20_VOL', 'Orchestra/RFTN20_VOL', 'Orchestra/PPF20_CE', 'Orchestra/RFTN20_CE', 'BIS/BIS'], 10)\n",
        "\n",
        "    # 결측값은 측정된 마지막 값으로 대체\n",
        "    vals = pd.DataFrame(vals).fillna(method='ffill').values\n",
        "    vals = np.nan_to_num(vals, 0)  # 맨 앞 쪽 결측값은 0으로 대체\n",
        "\n",
        "    # drug 주입을 하지 않은 case 혹은 bis를 사용하지 않은 case는 제외\n",
        "    if (np.max(vals, axis=0) <= 1).any():\n",
        "        print('no drug infusion or bis')\n",
        "        continue\n",
        "\n",
        "    # drug infusion 시작 시간을 구하고 그 이전을 삭제\n",
        "    first_ppf_idx = np.where(vals[:, PPF_DOSE] > 1)[0][0]\n",
        "    first_rft_idx = np.where(vals[:, RFT_DOSE] > 1)[0][0]\n",
        "    first_drug_idx = min(first_ppf_idx, first_rft_idx)\n",
        "    vals = vals[first_drug_idx:, :]\n",
        "\n",
        "    # volume 을 rate로 변경\n",
        "    vals[1:, PPF_DOSE] -= vals[:-1, PPF_DOSE]\n",
        "    vals[1:, RFT_DOSE] -= vals[:-1, RFT_DOSE]\n",
        "    vals[0, PPF_DOSE] = 0\n",
        "    vals[0, RFT_DOSE] = 0\n",
        "\n",
        "    # 음수 값(volume 감소)을 0으로 대체\n",
        "    vals[vals < 0] = 0\n",
        "\n",
        "    # bis 값의 첫 값이 80 이하이거나 마지막 값이 70 이하인 case는 사용하지 않음\n",
        "    valid_bis_idx = np.where(vals[:, BIS] > 0)[0]\n",
        "    first_bis_idx = valid_bis_idx[0]\n",
        "    last_bis_idx = valid_bis_idx[-1]\n",
        "    if vals[first_bis_idx, BIS] < 80:\n",
        "        print('first bis < 80')\n",
        "        continue\n",
        "    if vals[last_bis_idx, BIS] < 70:\n",
        "        print('last bis < 70')\n",
        "        continue\n",
        "\n",
        "    # infusion 시작 전 LSTM_TIMEPOINTS 동안의 dose와 bis를 모두 0으로 세팅\n",
        "    vals = np.vstack((np.zeros((LSTM_TIMEPOINTS - 1, vals.shape[1])), vals))\n",
        "\n",
        "    # 현 case의 나이, 성별, 키, 몸무게를 가져옴\n",
        "    aswh = df_cases.loc[df_cases['caseid'] == caseid, ['age','sex','weight','height']].values.astype(float).flatten()\n",
        "\n",
        "    # case 시작 부터 종료까지 dataset 에 넣음\n",
        "    for irow in range(1, vals.shape[0] - LSTM_TIMEPOINTS - 1):\n",
        "        bis = vals[irow + LSTM_TIMEPOINTS, BIS]\n",
        "        if bis == 0:\n",
        "            continue\n",
        "\n",
        "        # 데이터셋에 입력값을 넣음\n",
        "        x_ppf_dose.append(vals[irow:irow + LSTM_TIMEPOINTS, PPF_DOSE])\n",
        "        x_rft_dose.append(vals[irow:irow + LSTM_TIMEPOINTS, RFT_DOSE])\n",
        "\n",
        "        x_aswh.append(aswh)\n",
        "        x_caseid.append(caseid)\n",
        "        y.append(bis)\n",
        "\n",
        "        ppf_ce = vals[irow + LSTM_TIMEPOINTS, PPF_CE]\n",
        "        rft_ce = vals[irow + LSTM_TIMEPOINTS, RFT_CE]\n",
        "        y_old.append(0.98 * (1 + ppf_ce / 4.47 + rft_ce / 19.3) ** -1.43)\n",
        "\n",
        "    # 사용할 case\n",
        "    print('done')\n",
        "    icase += 1\n",
        "    if icase >= ncase:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading 4503 (0/50)...done\n",
            "loading 3779 (1/50)...first bis < 80\n",
            "loading 118 (1/50)...last bis < 70\n",
            "loading 5142 (1/50)...done\n",
            "loading 1665 (2/50)...done\n",
            "loading 3477 (3/50)...done\n",
            "loading 4241 (4/50)...done\n",
            "loading 2315 (5/50)...done\n",
            "loading 6235 (6/50)...done\n",
            "loading 54 (7/50)...done\n",
            "loading 6135 (8/50)...done\n",
            "loading 4236 (9/50)...done\n",
            "loading 1130 (10/50)...done\n",
            "loading 3452 (11/50)...first bis < 80\n",
            "loading 3887 (11/50)...last bis < 70\n",
            "loading 5368 (11/50)...first bis < 80\n",
            "loading 1661 (11/50)...first bis < 80\n",
            "loading 4746 (11/50)...done\n",
            "loading 6040 (12/50)...first bis < 80\n",
            "loading 4417 (12/50)...done\n",
            "loading 1078 (13/50)...done\n",
            "loading 1232 (14/50)...done\n",
            "loading 2185 (15/50)...no drug infusion or bis\n",
            "loading 193 (15/50)...done\n",
            "loading 5109 (16/50)...done\n",
            "loading 4836 (17/50)...done\n",
            "loading 48 (18/50)...done\n",
            "loading 1844 (19/50)...done\n",
            "loading 6157 (20/50)...done\n",
            "loading 2886 (21/50)...no drug infusion or bis\n",
            "loading 904 (21/50)...first bis < 80\n",
            "loading 5498 (21/50)...done\n",
            "loading 2308 (22/50)...done\n",
            "loading 3737 (23/50)...done\n",
            "loading 657 (24/50)...done\n",
            "loading 5814 (25/50)...first bis < 80\n",
            "loading 1558 (25/50)...last bis < 70\n",
            "loading 3256 (25/50)...first bis < 80\n",
            "loading 81 (25/50)...first bis < 80\n",
            "loading 5871 (25/50)...done\n",
            "loading 2580 (26/50)...first bis < 80\n",
            "loading 6155 (26/50)...done\n",
            "loading 6039 (27/50)...no drug infusion or bis\n",
            "loading 2944 (27/50)...done\n",
            "loading 4678 (28/50)...first bis < 80\n",
            "loading 5780 (28/50)...last bis < 70\n",
            "loading 1579 (28/50)...done\n",
            "loading 122 (29/50)...done\n",
            "loading 4416 (30/50)...done\n",
            "loading 3093 (31/50)...first bis < 80\n",
            "loading 2794 (31/50)...done\n",
            "loading 6110 (32/50)...done\n",
            "loading 1080 (33/50)...first bis < 80\n",
            "loading 6277 (33/50)...done\n",
            "loading 3950 (34/50)...done\n",
            "loading 5333 (35/50)...first bis < 80\n",
            "loading 2310 (35/50)...first bis < 80\n",
            "loading 3340 (35/50)...done\n",
            "loading 4803 (36/50)...done\n",
            "loading 4433 (37/50)...first bis < 80\n",
            "loading 5311 (37/50)...first bis < 80\n",
            "loading 2332 (37/50)...last bis < 70\n",
            "loading 1900 (37/50)...last bis < 70\n",
            "loading 4929 (37/50)...done\n",
            "loading 4768 (38/50)...done\n",
            "loading 804 (39/50)...done\n",
            "loading 4858 (40/50)...first bis < 80\n",
            "loading 2165 (40/50)...last bis < 70\n",
            "loading 3319 (40/50)...first bis < 80\n",
            "loading 6060 (40/50)...done\n",
            "loading 5508 (41/50)...done\n",
            "loading 2938 (42/50)...done\n",
            "loading 3712 (43/50)...done\n",
            "loading 3996 (44/50)...first bis < 80\n",
            "loading 2933 (44/50)...done\n",
            "loading 2641 (45/50)...done\n",
            "loading 5305 (46/50)...last bis < 70\n",
            "loading 68 (46/50)...done\n",
            "loading 2708 (47/50)...done\n",
            "loading 1298 (48/50)...done\n",
            "loading 136 (49/50)...done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwwLDouezDLc"
      },
      "source": [
        "## 데이터셋 포맷 및 차원 변환"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHa2fte0zGEv"
      },
      "source": [
        "# 결측값이 있으면 제거\n",
        "print('invalid samples...', end='', flush=True)\n",
        "valid_mask = ~(np.max(np.isnan(x), axis=1) > 0) # nan이 있으면 제거\n",
        "valid_mask &= (np.max(x, axis=1) - np.min(x, axis=1) > 12)  # bis 임피던스 체크 eeg의 전체 range가 12 미만이면 제거\n",
        "x = x[valid_mask, :]\n",
        "y = y[valid_mask]\n",
        "b = b[valid_mask]\n",
        "c = c[valid_mask]\n",
        "print('{:.1f}% removed'.format(100*(1-np.mean(valid_mask))))\n",
        "\n",
        "# 필터링\n",
        "print('baseline drift...', end='', flush=True)\n",
        "x -= scipy.signal.savgol_filter(x, 91, 3)  # remove baseline drift\n",
        "print('removed')\n",
        "\n",
        "# noise 가 많으면 제거\n",
        "print('noisy samples...', end='', flush=True)\n",
        "valid_mask = (np.nanmax(np.abs(x), axis=1) < 100) # noisy sample \n",
        "\n",
        "x = x[valid_mask, :]  # CNN 에 넣기 위해서는 3차원이어야 한다. 마지막 차원을 추가\n",
        "y = y[valid_mask]\n",
        "b = b[valid_mask]\n",
        "c = c[valid_mask]\n",
        "print('{:.1f}% removed'.format(100*(1-np.mean(valid_mask))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpMowosc0Bzf"
      },
      "source": [
        "## 데이터를 학습(train)과 테스트(test)로 나누기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjdvjsJ10JAe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dedf00e9-423c-4ad4-ab83-2f22b254f1be"
      },
      "source": [
        "# 최종적으로 로딩 된 caseid\n",
        "caseids = list(np.unique(c))\n",
        "random.shuffle(caseids)\n",
        "\n",
        "# case 단위로 train, test case로 나눔\n",
        "ntest = max(1, int(len(caseids) * 0.2))\n",
        "caseids_train = caseids[ntest:]\n",
        "caseids_test = caseids[:ntest]\n",
        "\n",
        "train_mask = np.isin(c, caseids_train)\n",
        "test_mask = np.isin(c, caseids_test)\n",
        "x_train = x[train_mask]\n",
        "y_train = y[train_mask]\n",
        "x_test = x[test_mask]\n",
        "y_test = y[test_mask]\n",
        "b_test = b[test_mask]\n",
        "c_test = c[test_mask]\n",
        "\n",
        "print('====================================================')\n",
        "print('total: {} cases {} samples'.format(len(caseids), len(y)))\n",
        "print('train: {} cases {} samples'.format(len(np.unique(c[train_mask])), len(y_train)))\n",
        "print('test {} cases {} samples'.format(len(np.unique(c_test)), len(y_test)))\n",
        "print('====================================================')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train: 45 cases 53222 samples, testing: 5 cases 5266 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPi6FIbB0NkF"
      },
      "source": [
        "# Model building\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uytYU2Fu0rPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c66ef36-c08e-4e18-8f25-6d6d3e912bef"
      },
      "source": [
        "import keras.models\n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Layer, LayerNormalization, Dense, Dropout, Conv1D, MaxPooling1D, GlobalAveragePooling1D, GlobalMaxPooling1D, Input, concatenate, multiply, dot, MultiHeadAttention\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# hyperparameters\n",
        "tests = {\n",
        "    \"nfilt\" : [16, 32, 64],\n",
        "    \"fnode\" : [32, 64, 128],\n",
        "    \"clayer\" : [1, 2, 3, 4],\n",
        "    \"droprate\" : [0.1, 0.2],\n",
        "    \"filtsize\" : [5, 7, 9, 11],\n",
        "    'poolsize' : [2, 4, 8],\n",
        "    \"pooltype\" : ['avg', 'max']\n",
        "}\n",
        "\n",
        "# https://keras.io/examples/nlp/text_classification_with_transformer/\n",
        "keys, values = zip(*tests.items())\n",
        "permutations_dicts = it.product(*values)\n",
        "permutations_dicts = list(permutations_dicts)\n",
        "random.shuffle(permutations_dicts)\n",
        "for nfilt, fnode, clayer, droprate, filtsize, poolsize, pooltype in permutations_dicts:\n",
        "\n",
        "    keras.backend.clear_session()\n",
        "    \n",
        "    odir = '{}cases_{}sec'.format(MAX_CASES, SEGLEN // SRATE)\n",
        "    odir += '_cnn{} filt{} size{} pool{} {} do{}'.format(clayer, nfilt, filtsize, poolsize, pooltype, droprate)\n",
        "    print(\"============================\")\n",
        "    print(odir)\n",
        "    print(\"============================\")\n",
        "\n",
        "    out = inp = Input(shape=(x_train.shape[1], 1))\n",
        "    out = Conv1D(filters=nfilt, kernel_size=filtsize, padding='same')(out)\n",
        "    # conv 여러층    \n",
        "    for i in range(clayer):\n",
        "        out = Conv1D(filters=nfilt, kernel_size=filtsize, padding='same', activation='relu')(out)\n",
        "        out = MaxPooling1D(poolsize, padding='same')(out)\n",
        "    if pooltype == \"avg\":\n",
        "        out = GlobalAveragePooling1D()(out)\n",
        "    else:\n",
        "        out = GlobalMaxPooling1D()(out)\n",
        "\n",
        "    if droprate:\n",
        "        out = Dropout(droprate)(out)\n",
        "    out = Dense(fnode)(out)\n",
        "    if droprate:\n",
        "        out = Dropout(droprate)(out)\n",
        "    out = Dense(1)(out)\n",
        "\n",
        "    if not os.path.exists(odir):\n",
        "        os.mkdir(odir)\n",
        "\n",
        "    cache_path = odir + \"/weights.hdf5\"\n",
        "    model = Model(inputs=[inp], outputs=[out])\n",
        "    model.summary()\n",
        "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
        "    hist = model.fit(x_train[..., None], y_train, validation_split=0.2, epochs=10, batch_size=BATCH_SIZE,\n",
        "                    callbacks=[ModelCheckpoint(monitor='val_loss', filepath=cache_path, verbose=1, save_best_only=True),\n",
        "                               EarlyStopping(monitor='val_loss', patience=1, verbose=1, mode='auto'),\n",
        "                               ])\n",
        "\n",
        "    # prediction\n",
        "    pred_test = model.predict(x_test[..., None], batch_size=BATCH_SIZE).flatten()\n",
        "\n",
        "    # 성능을 계산하여 출력\n",
        "    test_mae = np.mean(np.abs(y_test - pred_test))\n",
        "    for caseid in np.unique(c_test):\n",
        "        case_mask = (c_test == caseid)\n",
        "        pred_test[case_mask] = scipy.signal.medfilt(pred_test[case_mask], 31)\n",
        "\n",
        "    # prediction\n",
        "    for caseid in np.unique(c_test):\n",
        "        case_mask = (c_test == caseid)\n",
        "        case_len = np.sum(case_mask)\n",
        "        if case_len == 0:\n",
        "            continue\n",
        "\n",
        "        our_mae = np.mean(np.abs(y_test[case_mask] - pred_test[case_mask]))\n",
        "        print('Total MAE={:.4f}, CaseID {}, MAE={:.4f}'.format(test_mae, caseid, our_mae))\n",
        "\n",
        "        t = np.arange(0, case_len)\n",
        "        plt.figure(figsize=(20, 5))\n",
        "        plt.plot(t, y_test[case_mask], label='MAC')  # 측정 결과 \n",
        "        plt.plot(t, pred_test[case_mask], label='Ours ({:.4f})'.format(our_mae))\n",
        "        plt.legend(loc=\"upper left\")\n",
        "        plt.tight_layout()\n",
        "        plt.xlim([0, case_len])\n",
        "        plt.ylim([0, 2])\n",
        "        plt.savefig('{}/{:.4f}_{}.png'.format(odir, our_mae, caseid))\n",
        "        plt.close()\n",
        "\n",
        "    # 최종 디렉토리 이름 바꿈\n",
        "    os.rename(odir, '{:.4f}'.format(test_mae) + odir + '_' + str(random.randint(0, 1000)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 19s 110ms/step - loss: 0.1017 - mean_absolute_percentage_error: 23.7280 - val_loss: 0.1096 - val_mean_absolute_percentage_error: 30.3796\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0933 - mean_absolute_percentage_error: 21.3791 - val_loss: 0.1070 - val_mean_absolute_percentage_error: 29.2109\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0877 - mean_absolute_percentage_error: 20.2326 - val_loss: 0.0990 - val_mean_absolute_percentage_error: 28.2095\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0830 - mean_absolute_percentage_error: 19.7110 - val_loss: 0.0982 - val_mean_absolute_percentage_error: 28.2541\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0815 - mean_absolute_percentage_error: 19.4846 - val_loss: 0.0978 - val_mean_absolute_percentage_error: 28.3904\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0809 - mean_absolute_percentage_error: 19.3659 - val_loss: 0.0948 - val_mean_absolute_percentage_error: 27.6144\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0803 - mean_absolute_percentage_error: 19.2700 - val_loss: 0.0983 - val_mean_absolute_percentage_error: 28.3905\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0804 - mean_absolute_percentage_error: 19.2611 - val_loss: 0.0950 - val_mean_absolute_percentage_error: 27.9300\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 10s 102ms/step - loss: 0.0800 - mean_absolute_percentage_error: 19.1936 - val_loss: 0.0981 - val_mean_absolute_percentage_error: 28.8082\n"
          ]
        }
      ]
    }
  ]
}